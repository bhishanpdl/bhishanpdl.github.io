<h1 id="project-description">Project Description</h1>
<p>In this project I used the <a href="https://www.kaggle.com/blastchar/telco-customer-churn">Kaggle Customer Churn</a> data to determine whether the customer will churn (leave the company) or not. I splitted the kaggle training data into train and test (80%/20%) and fitted the models using train data and evaluated model results in test data.</p>
<h1 id="data-description">Data description</h1>
<p><img src="images/data_describe.png" /></p>
<h1 id="data-processing">Data Processing</h1>
<ul>
<li>Missing Value imputation for <code>TotalCharges</code> with 0.</li>
<li>Label Encoding for features having 5 or less unique values.</li>
<li>Binning Numerical Features.</li>
<li>Combination of features. e.g <code>SeniorCitizen + Dependents</code>.</li>
<li>Boolean Features. e.g.Â Does someone have Contract or not.</li>
<li>Aggregation features. eg. Mean of <code>TotalCharges</code> per <code>Contract</code>.</li>
</ul>
<h1 id="sklearn-methods-logistic-regression">Sklearn Methods: Logistic Regression</h1>
<ul>
<li>Used raw data with new features from EDA.</li>
<li>Used SMOTE oversampling since data is imbalanced.</li>
<li>Used <code>yeo-johnson</code> transformers instead of standard scaling since the numerical features were not normal.</li>
<li>Tuned the model using <a href="https://github.com/thuijskens/scikit-hyperband">hyperband</a> library.</li>
</ul>
<pre><code>      Accuracy  Precision Recall    F1-score    AUC
LR    0.4450    0.3075    0.8717    0.4547    0.5812

                    Predicted-noChurn  Predicted-Churn
Original no-Churn    [[301             734]
Original Churn       [ 48              326]]


 Lets choose cost of False Negative is 2$ and cost of False positive is 1$.
 cost = 48*2 + 734 = 830</code></pre>
<h1 id="boosting-xgboost">Boosting: Xgboost</h1>
<ul>
<li>Used minimal feature engineering.</li>
<li>Get dummy featrues using <code>drop_first=False</code></li>
<li>Used xgb classifier with validation set and eval metric <code>aucpr</code>.</li>
</ul>
<pre><code>         Accuracy Precision  Recall  F1-score AUC
xgboost  0.7417   0.5083     0.8235  0.6286   0.7678

[[737 298]
 [ 66 308]]

 cost = 66*2 + 298 = 430</code></pre>
<h1 id="modelling-pycaret">Modelling Pycaret</h1>
<ul>
<li>Used detailed cleaned data.</li>
<li>Pycaret uses gpu for xgboost and lightgbm in colab.</li>
<li>Pycaret does not have model interpretation (SHAP) for non-tree based models.</li>
<li>Simple model comparison gave naive bayes as the best model.</li>
<li>Used additional metrics <code>MCC and LogLoss</code>.</li>
<li>Used <code>tune-sklearn</code> algorithm to tune logistic regression.</li>
<li>The model calibration in pycaret DID NOT improve the metric.</li>
</ul>
<p><img src="images/pycaret_compare_models.png" /> <img src="images/pycaret_lr.png" /></p>
<pre><code>Pycaret Logistic Regression
==============================================================
            Accuracy Precision Recall    F1-score    AUC
pycaret_lr    0.7509 0.5199    0.8021    0.6309      0.7673

[[758 277]
 [ 74 300]]

cost = 74*2 + 277 = 425

Pycaret Naive Bayes
==============================================================
            Accuracy  Precision Recall    F1-score    AUC
pycaret_nb  0.7296    0.4943    0.8102    0.6140      0.7553
[[725 310]
 [ 71 303]]

cost = 71*2 + 310 = 452

Pycaret Xgboost (Takes long time, more than 1 hr)
===============================================================

                  Accuracy Precision Recall  F1-score  AUC
pycaret_xgboost    0.7601  0.5342    0.7513  0.6244    0.7573

[[790 245]
 [ 93 281]]
 cost = 93*2 + 245 = 431

 Pycaret LDA (Takes medium time, 5 mintues)
================================================================
- Used polynomial features and fix imbalanced data.

               Accuracy  Precision    Recall    F1-score  AUC
pycaret_lda    0.7062    0.4704       0.8503    0.6057    0.7522


[[677 358]
 [ 56 318]]

 cost = 56*2 + 358 = 470</code></pre>
<h1 id="deep-learning-models">Deep Learning models</h1>
<ul>
<li>Used minimal data processing.</li>
<li>Dropped <code>customerID</code> and <code>gender</code>.</li>
<li>Imputed <code>TotalCharges</code> with 0.</li>
<li>Created dummy variables from categorical features.</li>
<li>Used standard scaling to scale the data.</li>
<li>Used <code>class_weight</code> parameter to deal with imbalanced data.</li>
<li>Tuned keras model with scikitlearn <code>GridSearchCV</code></li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Model parameters</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>{<span class="st">&#39;activation&#39;</span>: <span class="st">&#39;sigmoid&#39;</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;batch_size&#39;</span>: <span class="dv">128</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;epochs&#39;</span>: <span class="dv">30</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;n_feats&#39;</span>: <span class="dv">43</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a> <span class="st">&#39;units&#39;</span>: (<span class="dv">45</span>, <span class="dv">30</span>, <span class="dv">15</span>)}</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>NOTE: The result changes each time even <span class="cf">if</span> I <span class="bu">set</span> SEED <span class="cf">for</span> everything.</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>      Accuracy  Precision Recall    F1<span class="op">-</span>score    AUC</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>keras <span class="fl">0.6849</span>    <span class="fl">0.4422</span>    <span class="fl">0.7166</span>    <span class="fl">0.5469</span>    <span class="fl">0.6950</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>[[<span class="dv">697</span> <span class="dv">338</span>]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a> [<span class="dv">106</span> <span class="dv">268</span>]]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>cost <span class="op">=</span> <span class="dv">106</span><span class="op">*</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">338</span> <span class="op">=</span> <span class="dv">550</span></span></code></pre></div>
<h1 id="model-comparion">Model Comparion</h1>
<pre><code>This is a imbalanced binary classification.
The useful metrics are AUC and Recall.

- The pure xgboost model gave me the best area under the curve (AUCROC).
- The pure logistic regression model gave me the best Recall.

Cost = False Negative * 2 + False Positive

                 Accuracy   Precision Recall       F1-score       AUC  Cost
pycaret_lr       0.750887   0.519931  0.802139     0.630915  0.767253  425
xgboost          0.741661   0.508251  0.823529     0.628571  0.767803  430
pycaret_xgboost  0.760114   0.534221  0.751337     0.624444  0.757311  431
pycaret_nb       0.729595   0.494290  0.810160     0.613982  0.755322  452
pycaret_lda      0.7062     0.4704    0.8503       0.6057    0.752200  470
keras            0.684883   0.442244  0.716578     0.546939  0.695004  550
LR               0.444996   0.307547  0.871658     0.454672  0.581240  830</code></pre>
